{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 下面代码的使用的目的是为了将EEGNet导入进来\n",
    "import sys\n",
    "sys.path.append(r'D:\\AI\\Python\\Work\\EEGNet-TensorFlow\\arl-eegmodels-master')\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# mne imports\n",
    "import mne\n",
    "from mne import io\n",
    "from mne.datasets import sample\n",
    "\n",
    "# EEGNet-specific imports\n",
    "from EEGModels import EEGNet\n",
    "from tensorflow.keras import utils as np_utils\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "K.set_image_data_format('channels_first')\n",
    "\n",
    "\n",
    "# PyRiemann imports\n",
    "from pyriemann.estimation import XdawnCovariances\n",
    "from pyriemann.tangentspace import TangentSpace\n",
    "from pyriemann.utils.viz import plot_confusion_matrix\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# tools for plotting confusion matrices\n",
    "from matplotlib import pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "##################### Process, filter and epoch the data ######################\n",
    "# data_path = sample.data_path()\n",
    "data_path = \"E:/MNE-sample-data\"\n",
    "\n",
    "# Set parameters and read data\n",
    "raw_fname = data_path + '/MEG/sample/sample_audvis_filt-0-40_raw.fif'\n",
    "event_fname = data_path + '/MEG/sample/sample_audvis_filt-0-40_raw-eve.fif'\n",
    "tmin, tmax = -0., 1\n",
    "event_id = dict(aud_l=1, aud_r=2, vis_l=3, vis_r=4)\n",
    "\n",
    "# Setup for reading the raw data\n",
    "raw = io.Raw(raw_fname, preload=True, verbose=False)\n",
    "raw.filter(2, None, method='iir')  # replace baselining with high-pass\n",
    "events = mne.read_events(event_fname)\n",
    "\n",
    "raw.info['bads'] = ['MEG 2443']  # set bad channels\n",
    "picks = mne.pick_types(raw.info, meg=False, eeg=True, stim=False, eog=False,\n",
    "                       exclude='bads')\n",
    "\n",
    "# Read epochs\n",
    "epochs = mne.Epochs(raw, events, event_id, tmin, tmax, proj=False,\n",
    "                    picks=picks, baseline=None, preload=True, verbose=False)\n",
    "labels = epochs.events[:, -1]\n",
    "\n",
    "# extract raw data. scale by 1000 due to scaling sensitivity in deep learning\n",
    "X = epochs.get_data() * 1000  # format is in (trials, channels, samples)\n",
    "y = labels\n",
    "\n",
    "kernels, chans, samples = 1, 60, 151\n",
    "\n",
    "# take 50/25/25 percent of the data to train/validate/test\n",
    "X_train = X[0:144, ]\n",
    "Y_train = y[0:144]\n",
    "X_validate = X[144:216, ]\n",
    "Y_validate = y[144:216]\n",
    "X_test = X[216:, ]\n",
    "Y_test = y[216:]\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (144, 1, 60, 151)\n",
      "144 train samples\n",
      "72 test samples\n"
     ]
    }
   ],
   "source": [
    "############################# EEGNet portion ##################################\n",
    "\n",
    "# convert labels to one-hot encodings.\n",
    "Y_train = np_utils.to_categorical(Y_train - 1)\n",
    "Y_validate = np_utils.to_categorical(Y_validate - 1)\n",
    "Y_test = np_utils.to_categorical(Y_test - 1)\n",
    "\n",
    "# convert data to NCHW (trials, kernels, channels, samples) format. Data\n",
    "# contains 60 channels and 151 time-points. Set the number of kernels to 1.\n",
    "X_train = X_train.reshape(X_train.shape[0], kernels, chans, samples)\n",
    "X_validate = X_validate.reshape(X_validate.shape[0], kernels, chans, samples)\n",
    "X_test = X_test.reshape(X_test.shape[0], kernels, chans, samples)\n",
    "\n",
    "print('X_train shape:', X_train.shape)\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')\n",
    "\n",
    "# configure the EEGNet-8,2,16 model with kernel length of 32 samples (other\n",
    "# model configurations may do better, but this is a good starting point)\n",
    "model = EEGNet(nb_classes=4, Chans=chans, Samples=samples,\n",
    "               dropoutRate=0.5, kernLength=32, F1=8, D=2, F2=16,\n",
    "               dropoutType='Dropout')\n",
    "\n",
    "# compile the model and set the optimizers\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# count number of parameters in the model\n",
    "numParams = model.count_params()\n",
    "\n",
    "# set a valid path for your system to record model checkpoints\n",
    "checkpointer = ModelCheckpoint(filepath='/tmp/checkpoint.h5', verbose=1,\n",
    "                               save_best_only=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0617 11:46:52.890793  4932 data_adapter.py:1091] sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "W0617 11:46:52.907747  4932 data_adapter.py:1091] sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 144 samples, validate on 72 samples\n",
      "Epoch 1/300\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.38628, saving model to /tmp/checkpoint.h5\n",
      "144/144 - 2s - loss: 1.4201 - accuracy: 0.2500 - val_loss: 1.3863 - val_accuracy: 0.2639\n",
      "Epoch 2/300\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.38628\n",
      "144/144 - 0s - loss: 1.3680 - accuracy: 0.3681 - val_loss: 1.3863 - val_accuracy: 0.2361\n",
      "Epoch 3/300\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.38628\n",
      "144/144 - 0s - loss: 1.3541 - accuracy: 0.3681 - val_loss: 1.3864 - val_accuracy: 0.2361\n",
      "Epoch 4/300\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.38628\n",
      "144/144 - 0s - loss: 1.3341 - accuracy: 0.4306 - val_loss: 1.3863 - val_accuracy: 0.2361\n",
      "Epoch 5/300\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.38628\n",
      "144/144 - 0s - loss: 1.3186 - accuracy: 0.4514 - val_loss: 1.3863 - val_accuracy: 0.2361\n",
      "Epoch 6/300\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.38628\n",
      "144/144 - 0s - loss: 1.2847 - accuracy: 0.4931 - val_loss: 1.3863 - val_accuracy: 0.2361\n",
      "Epoch 7/300\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.38628 to 1.38622, saving model to /tmp/checkpoint.h5\n",
      "144/144 - 0s - loss: 1.2530 - accuracy: 0.4861 - val_loss: 1.3862 - val_accuracy: 0.2361\n",
      "Epoch 8/300\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.38622 to 1.38606, saving model to /tmp/checkpoint.h5\n",
      "144/144 - 0s - loss: 1.2100 - accuracy: 0.5069 - val_loss: 1.3861 - val_accuracy: 0.2361\n",
      "Epoch 9/300\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.38606 to 1.38585, saving model to /tmp/checkpoint.h5\n",
      "144/144 - 0s - loss: 1.1829 - accuracy: 0.4792 - val_loss: 1.3858 - val_accuracy: 0.2361\n",
      "Epoch 10/300\n",
      "\n",
      "Epoch 00010: val_loss improved from 1.38585 to 1.38561, saving model to /tmp/checkpoint.h5\n",
      "144/144 - 0s - loss: 1.1535 - accuracy: 0.5417 - val_loss: 1.3856 - val_accuracy: 0.2361\n",
      "Epoch 11/300\n",
      "\n",
      "Epoch 00011: val_loss improved from 1.38561 to 1.38527, saving model to /tmp/checkpoint.h5\n",
      "144/144 - 0s - loss: 1.1259 - accuracy: 0.5069 - val_loss: 1.3853 - val_accuracy: 0.3194\n",
      "Epoch 12/300\n",
      "\n",
      "Epoch 00012: val_loss improved from 1.38527 to 1.38486, saving model to /tmp/checkpoint.h5\n",
      "144/144 - 0s - loss: 1.0775 - accuracy: 0.5833 - val_loss: 1.3849 - val_accuracy: 0.4028\n",
      "Epoch 13/300\n",
      "\n",
      "Epoch 00013: val_loss improved from 1.38486 to 1.38450, saving model to /tmp/checkpoint.h5\n",
      "144/144 - 0s - loss: 1.0806 - accuracy: 0.4861 - val_loss: 1.3845 - val_accuracy: 0.4028\n",
      "Epoch 14/300\n",
      "\n",
      "Epoch 00014: val_loss improved from 1.38450 to 1.38410, saving model to /tmp/checkpoint.h5\n",
      "144/144 - 0s - loss: 1.0489 - accuracy: 0.5625 - val_loss: 1.3841 - val_accuracy: 0.3750\n",
      "Epoch 15/300\n",
      "\n",
      "Epoch 00015: val_loss improved from 1.38410 to 1.38351, saving model to /tmp/checkpoint.h5\n",
      "144/144 - 0s - loss: 1.0529 - accuracy: 0.5486 - val_loss: 1.3835 - val_accuracy: 0.3750\n",
      "Epoch 16/300\n",
      "\n",
      "Epoch 00016: val_loss improved from 1.38351 to 1.38292, saving model to /tmp/checkpoint.h5\n",
      "144/144 - 0s - loss: 1.0181 - accuracy: 0.5139 - val_loss: 1.3829 - val_accuracy: 0.3611\n",
      "Epoch 17/300\n",
      "\n",
      "Epoch 00017: val_loss improved from 1.38292 to 1.38223, saving model to /tmp/checkpoint.h5\n",
      "144/144 - 0s - loss: 1.0169 - accuracy: 0.5972 - val_loss: 1.3822 - val_accuracy: 0.3889\n",
      "Epoch 18/300\n",
      "\n",
      "Epoch 00018: val_loss improved from 1.38223 to 1.38150, saving model to /tmp/checkpoint.h5\n",
      "144/144 - 0s - loss: 1.0192 - accuracy: 0.5069 - val_loss: 1.3815 - val_accuracy: 0.3750\n",
      "Epoch 19/300\n",
      "\n",
      "Epoch 00019: val_loss improved from 1.38150 to 1.38061, saving model to /tmp/checkpoint.h5\n",
      "144/144 - 0s - loss: 1.0135 - accuracy: 0.5486 - val_loss: 1.3806 - val_accuracy: 0.3611\n",
      "Epoch 20/300\n",
      "\n",
      "Epoch 00020: val_loss improved from 1.38061 to 1.37988, saving model to /tmp/checkpoint.h5\n",
      "144/144 - 0s - loss: 0.9946 - accuracy: 0.5278 - val_loss: 1.3799 - val_accuracy: 0.3611\n",
      "Epoch 21/300\n",
      "\n",
      "Epoch 00021: val_loss improved from 1.37988 to 1.37887, saving model to /tmp/checkpoint.h5\n",
      "144/144 - 0s - loss: 0.9998 - accuracy: 0.5903 - val_loss: 1.3789 - val_accuracy: 0.3750\n",
      "Epoch 22/300\n",
      "\n",
      "Epoch 00022: val_loss improved from 1.37887 to 1.37784, saving model to /tmp/checkpoint.h5\n",
      "144/144 - 0s - loss: 0.9946 - accuracy: 0.5764 - val_loss: 1.3778 - val_accuracy: 0.3750\n",
      "Epoch 23/300\n",
      "\n",
      "Epoch 00023: val_loss improved from 1.37784 to 1.37688, saving model to /tmp/checkpoint.h5\n",
      "144/144 - 0s - loss: 0.9734 - accuracy: 0.5556 - val_loss: 1.3769 - val_accuracy: 0.3750\n",
      "Epoch 24/300\n",
      "\n",
      "Epoch 00024: val_loss improved from 1.37688 to 1.37579, saving model to /tmp/checkpoint.h5\n",
      "144/144 - 0s - loss: 0.9670 - accuracy: 0.5347 - val_loss: 1.3758 - val_accuracy: 0.3750\n",
      "Epoch 25/300\n",
      "\n",
      "Epoch 00025: val_loss improved from 1.37579 to 1.37470, saving model to /tmp/checkpoint.h5\n",
      "144/144 - 0s - loss: 0.9612 - accuracy: 0.6042 - val_loss: 1.3747 - val_accuracy: 0.3611\n",
      "Epoch 26/300\n",
      "\n",
      "Epoch 00026: val_loss improved from 1.37470 to 1.37354, saving model to /tmp/checkpoint.h5\n",
      "144/144 - 0s - loss: 0.9841 - accuracy: 0.5556 - val_loss: 1.3735 - val_accuracy: 0.3611\n",
      "Epoch 27/300\n",
      "\n",
      "Epoch 00027: val_loss improved from 1.37354 to 1.37229, saving model to /tmp/checkpoint.h5\n",
      "144/144 - 0s - loss: 0.9499 - accuracy: 0.6389 - val_loss: 1.3723 - val_accuracy: 0.4028\n",
      "Epoch 28/300\n",
      "\n",
      "Epoch 00028: val_loss improved from 1.37229 to 1.37045, saving model to /tmp/checkpoint.h5\n",
      "144/144 - 0s - loss: 0.9619 - accuracy: 0.5625 - val_loss: 1.3704 - val_accuracy: 0.4306\n",
      "Epoch 29/300\n",
      "\n",
      "Epoch 00029: val_loss improved from 1.37045 to 1.36816, saving model to /tmp/checkpoint.h5\n",
      "144/144 - 0s - loss: 0.9859 - accuracy: 0.5486 - val_loss: 1.3682 - val_accuracy: 0.3611\n",
      "Epoch 30/300\n",
      "\n",
      "Epoch 00030: val_loss improved from 1.36816 to 1.36572, saving model to /tmp/checkpoint.h5\n",
      "144/144 - 0s - loss: 0.9618 - accuracy: 0.5903 - val_loss: 1.3657 - val_accuracy: 0.3889\n",
      "Epoch 31/300\n",
      "\n",
      "Epoch 00031: val_loss improved from 1.36572 to 1.36368, saving model to /tmp/checkpoint.h5\n",
      "144/144 - 0s - loss: 0.9415 - accuracy: 0.5694 - val_loss: 1.3637 - val_accuracy: 0.3472\n",
      "Epoch 32/300\n",
      "\n",
      "Epoch 00032: val_loss improved from 1.36368 to 1.36113, saving model to /tmp/checkpoint.h5\n",
      "144/144 - 0s - loss: 0.9262 - accuracy: 0.5972 - val_loss: 1.3611 - val_accuracy: 0.3750\n",
      "Epoch 33/300\n",
      "\n",
      "Epoch 00033: val_loss improved from 1.36113 to 1.35866, saving model to /tmp/checkpoint.h5\n",
      "144/144 - 0s - loss: 0.9322 - accuracy: 0.5625 - val_loss: 1.3587 - val_accuracy: 0.4028\n",
      "Epoch 34/300\n",
      "\n",
      "Epoch 00034: val_loss improved from 1.35866 to 1.35618, saving model to /tmp/checkpoint.h5\n",
      "144/144 - 0s - loss: 0.9177 - accuracy: 0.6181 - val_loss: 1.3562 - val_accuracy: 0.3472\n",
      "Epoch 35/300\n",
      "\n",
      "Epoch 00035: val_loss improved from 1.35618 to 1.35444, saving model to /tmp/checkpoint.h5\n",
      "144/144 - 0s - loss: 0.9003 - accuracy: 0.6319 - val_loss: 1.3544 - val_accuracy: 0.3611\n",
      "Epoch 36/300\n",
      "\n",
      "Epoch 00036: val_loss improved from 1.35444 to 1.35106, saving model to /tmp/checkpoint.h5\n",
      "144/144 - 1s - loss: 0.9165 - accuracy: 0.5833 - val_loss: 1.3511 - val_accuracy: 0.3889\n",
      "Epoch 37/300\n",
      "\n",
      "Epoch 00037: val_loss improved from 1.35106 to 1.34670, saving model to /tmp/checkpoint.h5\n",
      "144/144 - 0s - loss: 0.9114 - accuracy: 0.5972 - val_loss: 1.3467 - val_accuracy: 0.3750\n",
      "Epoch 38/300\n",
      "\n",
      "Epoch 00038: val_loss improved from 1.34670 to 1.34446, saving model to /tmp/checkpoint.h5\n",
      "144/144 - 0s - loss: 0.8981 - accuracy: 0.6389 - val_loss: 1.3445 - val_accuracy: 0.3611\n",
      "Epoch 39/300\n",
      "\n",
      "Epoch 00039: val_loss improved from 1.34446 to 1.33969, saving model to /tmp/checkpoint.h5\n",
      "144/144 - 0s - loss: 0.8924 - accuracy: 0.6111 - val_loss: 1.3397 - val_accuracy: 0.3611\n",
      "Epoch 40/300\n",
      "\n",
      "Epoch 00040: val_loss improved from 1.33969 to 1.33394, saving model to /tmp/checkpoint.h5\n",
      "144/144 - 0s - loss: 0.9214 - accuracy: 0.5903 - val_loss: 1.3339 - val_accuracy: 0.3889\n",
      "Epoch 41/300\n",
      "\n",
      "Epoch 00041: val_loss improved from 1.33394 to 1.33125, saving model to /tmp/checkpoint.h5\n",
      "144/144 - 0s - loss: 0.9004 - accuracy: 0.6111 - val_loss: 1.3312 - val_accuracy: 0.3750\n",
      "Epoch 42/300\n",
      "\n",
      "Epoch 00042: val_loss improved from 1.33125 to 1.32880, saving model to /tmp/checkpoint.h5\n",
      "144/144 - 0s - loss: 0.9281 - accuracy: 0.6181 - val_loss: 1.3288 - val_accuracy: 0.4028\n",
      "Epoch 43/300\n",
      "\n",
      "Epoch 00043: val_loss improved from 1.32880 to 1.32396, saving model to /tmp/checkpoint.h5\n",
      "144/144 - 0s - loss: 0.8908 - accuracy: 0.6181 - val_loss: 1.3240 - val_accuracy: 0.3750\n",
      "Epoch 44/300\n",
      "\n",
      "Epoch 00044: val_loss improved from 1.32396 to 1.32035, saving model to /tmp/checkpoint.h5\n",
      "144/144 - 0s - loss: 0.8961 - accuracy: 0.5972 - val_loss: 1.3204 - val_accuracy: 0.3611\n",
      "Epoch 45/300\n",
      "\n",
      "Epoch 00045: val_loss improved from 1.32035 to 1.31326, saving model to /tmp/checkpoint.h5\n",
      "144/144 - 0s - loss: 0.8865 - accuracy: 0.6042 - val_loss: 1.3133 - val_accuracy: 0.3750\n",
      "Epoch 46/300\n",
      "\n",
      "Epoch 00046: val_loss improved from 1.31326 to 1.30784, saving model to /tmp/checkpoint.h5\n",
      "144/144 - 0s - loss: 0.8502 - accuracy: 0.6875 - val_loss: 1.3078 - val_accuracy: 0.3611\n",
      "Epoch 47/300\n",
      "\n",
      "Epoch 00047: val_loss improved from 1.30784 to 1.30179, saving model to /tmp/checkpoint.h5\n",
      "144/144 - 0s - loss: 0.8738 - accuracy: 0.6458 - val_loss: 1.3018 - val_accuracy: 0.3889\n",
      "Epoch 48/300\n",
      "\n",
      "Epoch 00048: val_loss improved from 1.30179 to 1.29857, saving model to /tmp/checkpoint.h5\n",
      "144/144 - 0s - loss: 0.8830 - accuracy: 0.6875 - val_loss: 1.2986 - val_accuracy: 0.3611\n",
      "Epoch 49/300\n",
      "\n",
      "Epoch 00049: val_loss improved from 1.29857 to 1.29356, saving model to /tmp/checkpoint.h5\n",
      "144/144 - 0s - loss: 0.8515 - accuracy: 0.6528 - val_loss: 1.2936 - val_accuracy: 0.3611\n",
      "Epoch 50/300\n",
      "\n",
      "Epoch 00050: val_loss improved from 1.29356 to 1.27921, saving model to /tmp/checkpoint.h5\n",
      "144/144 - 0s - loss: 0.8641 - accuracy: 0.6111 - val_loss: 1.2792 - val_accuracy: 0.3750\n",
      "Epoch 51/300\n",
      "\n",
      "Epoch 00051: val_loss improved from 1.27921 to 1.27547, saving model to /tmp/checkpoint.h5\n",
      "144/144 - 0s - loss: 0.8531 - accuracy: 0.6806 - val_loss: 1.2755 - val_accuracy: 0.3750\n",
      "Epoch 52/300\n",
      "\n",
      "Epoch 00052: val_loss improved from 1.27547 to 1.26196, saving model to /tmp/checkpoint.h5\n",
      "144/144 - 0s - loss: 0.8643 - accuracy: 0.6597 - val_loss: 1.2620 - val_accuracy: 0.4028\n",
      "Epoch 53/300\n",
      "\n",
      "Epoch 00053: val_loss improved from 1.26196 to 1.25144, saving model to /tmp/checkpoint.h5\n",
      "144/144 - 0s - loss: 0.8273 - accuracy: 0.6667 - val_loss: 1.2514 - val_accuracy: 0.4028\n",
      "Epoch 54/300\n",
      "\n",
      "Epoch 00054: val_loss improved from 1.25144 to 1.24335, saving model to /tmp/checkpoint.h5\n",
      "144/144 - 0s - loss: 0.8323 - accuracy: 0.6736 - val_loss: 1.2433 - val_accuracy: 0.3750\n",
      "Epoch 55/300\n",
      "\n",
      "Epoch 00055: val_loss improved from 1.24335 to 1.23337, saving model to /tmp/checkpoint.h5\n",
      "144/144 - 0s - loss: 0.8309 - accuracy: 0.6597 - val_loss: 1.2334 - val_accuracy: 0.4306\n",
      "Epoch 56/300\n",
      "\n",
      "Epoch 00056: val_loss improved from 1.23337 to 1.22769, saving model to /tmp/checkpoint.h5\n",
      "144/144 - 0s - loss: 0.8283 - accuracy: 0.6736 - val_loss: 1.2277 - val_accuracy: 0.4028\n",
      "Epoch 57/300\n",
      "\n",
      "Epoch 00057: val_loss improved from 1.22769 to 1.21530, saving model to /tmp/checkpoint.h5\n",
      "144/144 - 0s - loss: 0.8249 - accuracy: 0.6806 - val_loss: 1.2153 - val_accuracy: 0.4444\n",
      "Epoch 58/300\n",
      "\n",
      "Epoch 00058: val_loss improved from 1.21530 to 1.19795, saving model to /tmp/checkpoint.h5\n",
      "144/144 - 0s - loss: 0.8333 - accuracy: 0.7014 - val_loss: 1.1980 - val_accuracy: 0.3750\n",
      "Epoch 59/300\n",
      "\n",
      "Epoch 00059: val_loss improved from 1.19795 to 1.18441, saving model to /tmp/checkpoint.h5\n",
      "144/144 - 0s - loss: 0.8423 - accuracy: 0.6111 - val_loss: 1.1844 - val_accuracy: 0.4583\n",
      "Epoch 60/300\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 1.18441\n",
      "144/144 - 0s - loss: 0.8364 - accuracy: 0.7014 - val_loss: 1.1895 - val_accuracy: 0.4306\n",
      "Epoch 61/300\n",
      "\n",
      "Epoch 00061: val_loss improved from 1.18441 to 1.16137, saving model to /tmp/checkpoint.h5\n",
      "144/144 - 0s - loss: 0.8425 - accuracy: 0.6667 - val_loss: 1.1614 - val_accuracy: 0.4444\n",
      "Epoch 62/300\n",
      "\n",
      "Epoch 00062: val_loss improved from 1.16137 to 1.15507, saving model to /tmp/checkpoint.h5\n",
      "144/144 - 0s - loss: 0.8049 - accuracy: 0.6806 - val_loss: 1.1551 - val_accuracy: 0.5000\n",
      "Epoch 63/300\n",
      "\n",
      "Epoch 00063: val_loss improved from 1.15507 to 1.13528, saving model to /tmp/checkpoint.h5\n",
      "144/144 - 0s - loss: 0.8264 - accuracy: 0.6458 - val_loss: 1.1353 - val_accuracy: 0.4861\n",
      "Epoch 64/300\n",
      "\n",
      "Epoch 00064: val_loss improved from 1.13528 to 1.12988, saving model to /tmp/checkpoint.h5\n",
      "144/144 - 0s - loss: 0.7979 - accuracy: 0.7083 - val_loss: 1.1299 - val_accuracy: 0.5278\n",
      "Epoch 65/300\n",
      "\n",
      "Epoch 00065: val_loss improved from 1.12988 to 1.11763, saving model to /tmp/checkpoint.h5\n",
      "144/144 - 0s - loss: 0.8016 - accuracy: 0.7153 - val_loss: 1.1176 - val_accuracy: 0.5417\n",
      "Epoch 66/300\n",
      "\n",
      "Epoch 00066: val_loss improved from 1.11763 to 1.10989, saving model to /tmp/checkpoint.h5\n",
      "144/144 - 0s - loss: 0.8204 - accuracy: 0.6250 - val_loss: 1.1099 - val_accuracy: 0.5417\n",
      "Epoch 67/300\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 1.10989\n",
      "144/144 - 0s - loss: 0.8050 - accuracy: 0.6667 - val_loss: 1.1142 - val_accuracy: 0.5139\n",
      "Epoch 68/300\n",
      "\n",
      "Epoch 00068: val_loss improved from 1.10989 to 1.08090, saving model to /tmp/checkpoint.h5\n",
      "144/144 - 0s - loss: 0.8064 - accuracy: 0.7083 - val_loss: 1.0809 - val_accuracy: 0.5972\n",
      "Epoch 69/300\n",
      "\n",
      "Epoch 00069: val_loss improved from 1.08090 to 1.07916, saving model to /tmp/checkpoint.h5\n",
      "144/144 - 0s - loss: 0.8156 - accuracy: 0.7083 - val_loss: 1.0792 - val_accuracy: 0.5000\n",
      "Epoch 70/300\n",
      "\n",
      "Epoch 00070: val_loss improved from 1.07916 to 1.07521, saving model to /tmp/checkpoint.h5\n",
      "144/144 - 0s - loss: 0.7933 - accuracy: 0.7083 - val_loss: 1.0752 - val_accuracy: 0.5139\n",
      "Epoch 71/300\n",
      "\n",
      "Epoch 00071: val_loss improved from 1.07521 to 1.05067, saving model to /tmp/checkpoint.h5\n",
      "144/144 - 0s - loss: 0.8276 - accuracy: 0.6806 - val_loss: 1.0507 - val_accuracy: 0.5556\n",
      "Epoch 72/300\n",
      "\n",
      "Epoch 00072: val_loss improved from 1.05067 to 1.04920, saving model to /tmp/checkpoint.h5\n",
      "144/144 - 0s - loss: 0.7615 - accuracy: 0.7639 - val_loss: 1.0492 - val_accuracy: 0.5139\n",
      "Epoch 73/300\n",
      "\n",
      "Epoch 00073: val_loss improved from 1.04920 to 1.02642, saving model to /tmp/checkpoint.h5\n",
      "144/144 - 0s - loss: 0.7635 - accuracy: 0.7153 - val_loss: 1.0264 - val_accuracy: 0.5972\n",
      "Epoch 74/300\n",
      "\n",
      "Epoch 00074: val_loss improved from 1.02642 to 1.00999, saving model to /tmp/checkpoint.h5\n",
      "144/144 - 0s - loss: 0.7680 - accuracy: 0.7917 - val_loss: 1.0100 - val_accuracy: 0.6389\n",
      "Epoch 75/300\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 1.00999\n",
      "144/144 - 0s - loss: 0.7670 - accuracy: 0.7431 - val_loss: 1.0355 - val_accuracy: 0.5556\n",
      "Epoch 76/300\n",
      "\n",
      "Epoch 00076: val_loss improved from 1.00999 to 1.00311, saving model to /tmp/checkpoint.h5\n",
      "144/144 - 0s - loss: 0.7901 - accuracy: 0.6875 - val_loss: 1.0031 - val_accuracy: 0.6528\n",
      "Epoch 77/300\n",
      "\n",
      "Epoch 00077: val_loss improved from 1.00311 to 0.97806, saving model to /tmp/checkpoint.h5\n",
      "144/144 - 0s - loss: 0.7644 - accuracy: 0.7431 - val_loss: 0.9781 - val_accuracy: 0.6389\n",
      "Epoch 78/300\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.97806\n",
      "144/144 - 0s - loss: 0.7592 - accuracy: 0.7222 - val_loss: 0.9832 - val_accuracy: 0.5417\n",
      "Epoch 79/300\n",
      "\n",
      "Epoch 00079: val_loss improved from 0.97806 to 0.95391, saving model to /tmp/checkpoint.h5\n",
      "144/144 - 0s - loss: 0.7679 - accuracy: 0.7222 - val_loss: 0.9539 - val_accuracy: 0.5972\n",
      "Epoch 80/300\n",
      "\n",
      "Epoch 00080: val_loss improved from 0.95391 to 0.94984, saving model to /tmp/checkpoint.h5\n",
      "144/144 - 0s - loss: 0.7741 - accuracy: 0.7708 - val_loss: 0.9498 - val_accuracy: 0.6806\n",
      "Epoch 81/300\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.94984\n",
      "144/144 - 0s - loss: 0.7600 - accuracy: 0.7361 - val_loss: 0.9617 - val_accuracy: 0.6111\n",
      "Epoch 82/300\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.94984\n",
      "144/144 - 0s - loss: 0.7574 - accuracy: 0.7292 - val_loss: 0.9522 - val_accuracy: 0.6528\n",
      "Epoch 83/300\n",
      "\n",
      "Epoch 00083: val_loss improved from 0.94984 to 0.93624, saving model to /tmp/checkpoint.h5\n",
      "144/144 - 0s - loss: 0.7108 - accuracy: 0.7778 - val_loss: 0.9362 - val_accuracy: 0.6528\n",
      "Epoch 84/300\n",
      "\n",
      "Epoch 00084: val_loss improved from 0.93624 to 0.92686, saving model to /tmp/checkpoint.h5\n",
      "144/144 - 0s - loss: 0.7042 - accuracy: 0.7847 - val_loss: 0.9269 - val_accuracy: 0.6111\n",
      "Epoch 85/300\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.92686\n",
      "144/144 - 0s - loss: 0.7350 - accuracy: 0.7500 - val_loss: 0.9367 - val_accuracy: 0.6250\n",
      "Epoch 86/300\n",
      "\n",
      "Epoch 00086: val_loss improved from 0.92686 to 0.90403, saving model to /tmp/checkpoint.h5\n",
      "144/144 - 0s - loss: 0.7184 - accuracy: 0.7778 - val_loss: 0.9040 - val_accuracy: 0.6528\n",
      "Epoch 87/300\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.90403\n",
      "144/144 - 0s - loss: 0.6970 - accuracy: 0.7917 - val_loss: 0.9136 - val_accuracy: 0.6389\n",
      "Epoch 88/300\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.90403\n",
      "144/144 - 0s - loss: 0.7472 - accuracy: 0.7639 - val_loss: 0.9292 - val_accuracy: 0.6250\n",
      "Epoch 89/300\n",
      "\n",
      "Epoch 00089: val_loss improved from 0.90403 to 0.88184, saving model to /tmp/checkpoint.h5\n",
      "144/144 - 0s - loss: 0.6840 - accuracy: 0.8194 - val_loss: 0.8818 - val_accuracy: 0.6944\n",
      "Epoch 90/300\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.88184\n",
      "144/144 - 0s - loss: 0.6965 - accuracy: 0.7431 - val_loss: 0.9061 - val_accuracy: 0.6250\n",
      "Epoch 91/300\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.88184\n",
      "144/144 - 0s - loss: 0.7095 - accuracy: 0.7500 - val_loss: 0.8907 - val_accuracy: 0.6944\n",
      "Epoch 92/300\n",
      "\n",
      "Epoch 00092: val_loss improved from 0.88184 to 0.87317, saving model to /tmp/checkpoint.h5\n",
      "144/144 - 0s - loss: 0.6931 - accuracy: 0.8056 - val_loss: 0.8732 - val_accuracy: 0.6806\n",
      "Epoch 93/300\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.87317\n",
      "144/144 - 0s - loss: 0.6788 - accuracy: 0.8333 - val_loss: 0.8895 - val_accuracy: 0.6528\n",
      "Epoch 94/300\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.87317\n",
      "144/144 - 0s - loss: 0.6946 - accuracy: 0.8125 - val_loss: 0.8781 - val_accuracy: 0.6667\n",
      "Epoch 95/300\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.87317\n",
      "144/144 - 0s - loss: 0.7007 - accuracy: 0.7917 - val_loss: 0.8737 - val_accuracy: 0.7083\n",
      "Epoch 96/300\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.87317\n",
      "144/144 - 0s - loss: 0.6879 - accuracy: 0.8333 - val_loss: 0.8803 - val_accuracy: 0.6667\n",
      "Epoch 97/300\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.87317\n",
      "144/144 - 0s - loss: 0.7057 - accuracy: 0.7778 - val_loss: 0.8779 - val_accuracy: 0.6944\n",
      "Epoch 98/300\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.87317\n",
      "144/144 - 0s - loss: 0.6905 - accuracy: 0.7569 - val_loss: 0.8735 - val_accuracy: 0.6389\n",
      "Epoch 99/300\n",
      "\n",
      "Epoch 00099: val_loss improved from 0.87317 to 0.86675, saving model to /tmp/checkpoint.h5\n",
      "144/144 - 0s - loss: 0.6670 - accuracy: 0.8125 - val_loss: 0.8667 - val_accuracy: 0.6250\n",
      "Epoch 100/300\n",
      "\n",
      "Epoch 00100: val_loss improved from 0.86675 to 0.83810, saving model to /tmp/checkpoint.h5\n",
      "144/144 - 0s - loss: 0.6660 - accuracy: 0.7778 - val_loss: 0.8381 - val_accuracy: 0.6667\n",
      "Epoch 101/300\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 0.83810\n",
      "144/144 - 0s - loss: 0.6656 - accuracy: 0.8194 - val_loss: 0.8444 - val_accuracy: 0.6667\n",
      "Epoch 102/300\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 0.83810\n",
      "144/144 - 0s - loss: 0.6728 - accuracy: 0.8056 - val_loss: 0.8549 - val_accuracy: 0.6528\n",
      "Epoch 103/300\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 0.83810\n",
      "144/144 - 0s - loss: 0.6394 - accuracy: 0.7847 - val_loss: 0.8527 - val_accuracy: 0.6944\n",
      "Epoch 104/300\n",
      "\n",
      "Epoch 00104: val_loss improved from 0.83810 to 0.82079, saving model to /tmp/checkpoint.h5\n",
      "144/144 - 0s - loss: 0.6197 - accuracy: 0.8264 - val_loss: 0.8208 - val_accuracy: 0.7083\n",
      "Epoch 105/300\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 0.82079\n",
      "144/144 - 0s - loss: 0.6596 - accuracy: 0.8125 - val_loss: 0.8559 - val_accuracy: 0.6806\n",
      "Epoch 106/300\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 0.82079\n",
      "144/144 - 0s - loss: 0.6315 - accuracy: 0.8056 - val_loss: 0.8620 - val_accuracy: 0.6528\n",
      "Epoch 107/300\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 0.82079\n",
      "144/144 - 0s - loss: 0.6615 - accuracy: 0.8125 - val_loss: 0.8269 - val_accuracy: 0.7222\n",
      "Epoch 108/300\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 0.82079\n",
      "144/144 - 0s - loss: 0.6446 - accuracy: 0.7986 - val_loss: 0.8433 - val_accuracy: 0.7222\n",
      "Epoch 109/300\n",
      "\n",
      "Epoch 00109: val_loss improved from 0.82079 to 0.79901, saving model to /tmp/checkpoint.h5\n",
      "144/144 - 0s - loss: 0.6330 - accuracy: 0.8056 - val_loss: 0.7990 - val_accuracy: 0.7083\n",
      "Epoch 110/300\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 0.79901\n",
      "144/144 - 0s - loss: 0.6370 - accuracy: 0.8264 - val_loss: 0.8360 - val_accuracy: 0.7361\n",
      "Epoch 111/300\n",
      "\n",
      "Epoch 00111: val_loss improved from 0.79901 to 0.79834, saving model to /tmp/checkpoint.h5\n",
      "144/144 - 0s - loss: 0.6229 - accuracy: 0.8403 - val_loss: 0.7983 - val_accuracy: 0.6528\n",
      "Epoch 112/300\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 0.79834\n",
      "144/144 - 0s - loss: 0.6290 - accuracy: 0.8333 - val_loss: 0.8327 - val_accuracy: 0.6944\n",
      "Epoch 113/300\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 0.79834\n",
      "144/144 - 0s - loss: 0.6079 - accuracy: 0.8403 - val_loss: 0.8177 - val_accuracy: 0.7083\n",
      "Epoch 114/300\n",
      "\n",
      "Epoch 00114: val_loss improved from 0.79834 to 0.76364, saving model to /tmp/checkpoint.h5\n",
      "144/144 - 0s - loss: 0.6391 - accuracy: 0.7847 - val_loss: 0.7636 - val_accuracy: 0.7639\n",
      "Epoch 115/300\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 0.76364\n",
      "144/144 - 0s - loss: 0.5972 - accuracy: 0.8194 - val_loss: 0.8625 - val_accuracy: 0.6667\n",
      "Epoch 116/300\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 0.76364\n",
      "144/144 - 0s - loss: 0.6424 - accuracy: 0.8403 - val_loss: 0.8033 - val_accuracy: 0.6389\n",
      "Epoch 117/300\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 0.76364\n",
      "144/144 - 0s - loss: 0.6567 - accuracy: 0.7708 - val_loss: 0.7900 - val_accuracy: 0.7778\n",
      "Epoch 118/300\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 0.76364\n",
      "144/144 - 0s - loss: 0.5989 - accuracy: 0.8472 - val_loss: 0.7817 - val_accuracy: 0.7361\n",
      "Epoch 119/300\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 0.76364\n",
      "144/144 - 0s - loss: 0.5823 - accuracy: 0.8472 - val_loss: 0.8031 - val_accuracy: 0.6944\n",
      "Epoch 120/300\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 0.76364\n",
      "144/144 - 0s - loss: 0.6150 - accuracy: 0.8403 - val_loss: 0.8046 - val_accuracy: 0.7222\n",
      "Epoch 121/300\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 0.76364\n",
      "144/144 - 0s - loss: 0.5794 - accuracy: 0.8264 - val_loss: 0.8120 - val_accuracy: 0.7083\n",
      "Epoch 122/300\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 0.76364\n",
      "144/144 - 0s - loss: 0.5960 - accuracy: 0.8819 - val_loss: 0.7817 - val_accuracy: 0.7222\n",
      "Epoch 123/300\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 0.76364\n",
      "144/144 - 0s - loss: 0.5455 - accuracy: 0.8681 - val_loss: 0.7757 - val_accuracy: 0.7361\n",
      "Epoch 124/300\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 0.76364\n",
      "144/144 - 0s - loss: 0.5673 - accuracy: 0.8681 - val_loss: 0.8076 - val_accuracy: 0.7361\n",
      "Epoch 125/300\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 0.76364\n",
      "144/144 - 0s - loss: 0.5758 - accuracy: 0.8264 - val_loss: 0.7862 - val_accuracy: 0.7361\n",
      "Epoch 126/300\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 0.76364\n",
      "144/144 - 0s - loss: 0.5592 - accuracy: 0.8194 - val_loss: 0.7736 - val_accuracy: 0.7639\n",
      "Epoch 127/300\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 0.76364\n",
      "144/144 - 0s - loss: 0.5955 - accuracy: 0.8403 - val_loss: 0.7657 - val_accuracy: 0.7778\n",
      "Epoch 128/300\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 0.76364\n",
      "144/144 - 0s - loss: 0.5538 - accuracy: 0.8403 - val_loss: 0.7913 - val_accuracy: 0.7361\n",
      "Epoch 129/300\n",
      "\n",
      "Epoch 00129: val_loss improved from 0.76364 to 0.74282, saving model to /tmp/checkpoint.h5\n",
      "144/144 - 0s - loss: 0.5816 - accuracy: 0.8611 - val_loss: 0.7428 - val_accuracy: 0.7500\n",
      "Epoch 130/300\n",
      "\n",
      "Epoch 00130: val_loss improved from 0.74282 to 0.74279, saving model to /tmp/checkpoint.h5\n",
      "144/144 - 0s - loss: 0.5716 - accuracy: 0.8403 - val_loss: 0.7428 - val_accuracy: 0.7639\n",
      "Epoch 131/300\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 0.74279\n",
      "144/144 - 0s - loss: 0.5814 - accuracy: 0.8194 - val_loss: 0.7739 - val_accuracy: 0.7361\n",
      "Epoch 132/300\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 0.74279\n",
      "144/144 - 0s - loss: 0.5859 - accuracy: 0.8125 - val_loss: 0.7667 - val_accuracy: 0.7639\n",
      "Epoch 133/300\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 0.74279\n",
      "144/144 - 0s - loss: 0.5245 - accuracy: 0.8681 - val_loss: 0.7773 - val_accuracy: 0.7361\n",
      "Epoch 134/300\n",
      "\n",
      "Epoch 00134: val_loss improved from 0.74279 to 0.71510, saving model to /tmp/checkpoint.h5\n",
      "144/144 - 0s - loss: 0.5735 - accuracy: 0.8264 - val_loss: 0.7151 - val_accuracy: 0.7500\n",
      "Epoch 135/300\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 0.71510\n",
      "144/144 - 0s - loss: 0.5718 - accuracy: 0.8056 - val_loss: 0.7368 - val_accuracy: 0.7639\n",
      "Epoch 136/300\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 0.71510\n",
      "144/144 - 0s - loss: 0.5495 - accuracy: 0.8542 - val_loss: 0.7423 - val_accuracy: 0.7639\n",
      "Epoch 137/300\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 0.71510\n",
      "144/144 - 0s - loss: 0.5118 - accuracy: 0.8750 - val_loss: 0.7287 - val_accuracy: 0.7778\n",
      "Epoch 138/300\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 0.71510\n",
      "144/144 - 0s - loss: 0.5525 - accuracy: 0.8194 - val_loss: 0.7473 - val_accuracy: 0.7500\n",
      "Epoch 139/300\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 0.71510\n",
      "144/144 - 0s - loss: 0.5868 - accuracy: 0.7847 - val_loss: 0.7416 - val_accuracy: 0.7639\n",
      "Epoch 140/300\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 0.71510\n",
      "144/144 - 0s - loss: 0.4892 - accuracy: 0.9097 - val_loss: 0.7792 - val_accuracy: 0.7361\n",
      "Epoch 141/300\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 0.71510\n",
      "144/144 - 0s - loss: 0.5405 - accuracy: 0.8542 - val_loss: 0.7706 - val_accuracy: 0.7361\n",
      "Epoch 142/300\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 0.71510\n",
      "144/144 - 0s - loss: 0.5089 - accuracy: 0.8681 - val_loss: 0.7752 - val_accuracy: 0.7361\n",
      "Epoch 143/300\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 0.71510\n",
      "144/144 - 0s - loss: 0.5498 - accuracy: 0.8264 - val_loss: 0.7464 - val_accuracy: 0.7361\n",
      "Epoch 144/300\n",
      "\n",
      "Epoch 00144: val_loss improved from 0.71510 to 0.70113, saving model to /tmp/checkpoint.h5\n",
      "144/144 - 0s - loss: 0.5424 - accuracy: 0.8403 - val_loss: 0.7011 - val_accuracy: 0.7500\n",
      "Epoch 145/300\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 0.70113\n",
      "144/144 - 0s - loss: 0.5668 - accuracy: 0.8403 - val_loss: 0.7255 - val_accuracy: 0.7500\n",
      "Epoch 146/300\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 0.70113\n",
      "144/144 - 0s - loss: 0.5034 - accuracy: 0.8750 - val_loss: 0.8069 - val_accuracy: 0.7083\n",
      "Epoch 147/300\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 0.70113\n",
      "144/144 - 0s - loss: 0.4897 - accuracy: 0.8611 - val_loss: 0.7547 - val_accuracy: 0.7083\n",
      "Epoch 148/300\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 0.70113\n",
      "144/144 - 0s - loss: 0.5262 - accuracy: 0.8542 - val_loss: 0.7080 - val_accuracy: 0.7778\n",
      "Epoch 149/300\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 0.70113\n",
      "144/144 - 0s - loss: 0.5376 - accuracy: 0.8403 - val_loss: 0.7094 - val_accuracy: 0.7639\n",
      "Epoch 150/300\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 0.70113\n",
      "144/144 - 0s - loss: 0.4802 - accuracy: 0.8750 - val_loss: 0.7099 - val_accuracy: 0.7500\n",
      "Epoch 151/300\n",
      "\n",
      "Epoch 00151: val_loss improved from 0.70113 to 0.69921, saving model to /tmp/checkpoint.h5\n",
      "144/144 - 0s - loss: 0.5236 - accuracy: 0.8681 - val_loss: 0.6992 - val_accuracy: 0.7778\n",
      "Epoch 152/300\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 0.69921\n",
      "144/144 - 0s - loss: 0.4787 - accuracy: 0.8750 - val_loss: 0.7005 - val_accuracy: 0.8056\n",
      "Epoch 153/300\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 0.69921\n",
      "144/144 - 0s - loss: 0.4749 - accuracy: 0.8819 - val_loss: 0.7290 - val_accuracy: 0.7361\n",
      "Epoch 154/300\n",
      "\n",
      "Epoch 00154: val_loss improved from 0.69921 to 0.68599, saving model to /tmp/checkpoint.h5\n",
      "144/144 - 0s - loss: 0.5055 - accuracy: 0.8472 - val_loss: 0.6860 - val_accuracy: 0.7917\n",
      "Epoch 155/300\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 0.68599\n",
      "144/144 - 0s - loss: 0.5150 - accuracy: 0.8819 - val_loss: 0.7129 - val_accuracy: 0.7639\n",
      "Epoch 156/300\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 0.68599\n",
      "144/144 - 0s - loss: 0.5194 - accuracy: 0.8194 - val_loss: 0.7116 - val_accuracy: 0.7361\n",
      "Epoch 157/300\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 0.68599\n",
      "144/144 - 0s - loss: 0.5025 - accuracy: 0.9375 - val_loss: 0.6988 - val_accuracy: 0.7500\n",
      "Epoch 158/300\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 0.68599\n",
      "144/144 - 0s - loss: 0.4936 - accuracy: 0.8889 - val_loss: 0.6939 - val_accuracy: 0.7639\n",
      "Epoch 159/300\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 0.68599\n",
      "144/144 - 0s - loss: 0.4930 - accuracy: 0.8611 - val_loss: 0.6940 - val_accuracy: 0.7361\n",
      "Epoch 160/300\n",
      "\n",
      "Epoch 00160: val_loss improved from 0.68599 to 0.66463, saving model to /tmp/checkpoint.h5\n",
      "144/144 - 0s - loss: 0.4936 - accuracy: 0.8403 - val_loss: 0.6646 - val_accuracy: 0.8056\n",
      "Epoch 161/300\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 0.66463\n",
      "144/144 - 0s - loss: 0.4370 - accuracy: 0.8889 - val_loss: 0.6771 - val_accuracy: 0.7778\n",
      "Epoch 162/300\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 0.66463\n",
      "144/144 - 0s - loss: 0.4351 - accuracy: 0.9306 - val_loss: 0.6916 - val_accuracy: 0.7500\n",
      "Epoch 163/300\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 0.66463\n",
      "144/144 - 0s - loss: 0.5117 - accuracy: 0.8403 - val_loss: 0.6699 - val_accuracy: 0.7500\n",
      "Epoch 164/300\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 0.66463\n",
      "144/144 - 0s - loss: 0.5087 - accuracy: 0.8056 - val_loss: 0.6867 - val_accuracy: 0.7639\n",
      "Epoch 165/300\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 0.66463\n",
      "144/144 - 0s - loss: 0.4772 - accuracy: 0.8681 - val_loss: 0.7022 - val_accuracy: 0.7778\n",
      "Epoch 166/300\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 0.66463\n",
      "144/144 - 0s - loss: 0.4328 - accuracy: 0.8889 - val_loss: 0.6888 - val_accuracy: 0.7500\n",
      "Epoch 167/300\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 0.66463\n",
      "144/144 - 0s - loss: 0.4380 - accuracy: 0.9028 - val_loss: 0.6921 - val_accuracy: 0.7222\n",
      "Epoch 168/300\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 0.66463\n",
      "144/144 - 0s - loss: 0.4573 - accuracy: 0.9097 - val_loss: 0.7007 - val_accuracy: 0.7500\n",
      "Epoch 169/300\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 0.66463\n",
      "144/144 - 0s - loss: 0.4598 - accuracy: 0.8750 - val_loss: 0.6667 - val_accuracy: 0.7778\n",
      "Epoch 170/300\n",
      "\n",
      "Epoch 00170: val_loss improved from 0.66463 to 0.64237, saving model to /tmp/checkpoint.h5\n",
      "144/144 - 0s - loss: 0.4331 - accuracy: 0.9167 - val_loss: 0.6424 - val_accuracy: 0.8056\n",
      "Epoch 171/300\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 0.64237\n",
      "144/144 - 0s - loss: 0.4897 - accuracy: 0.8750 - val_loss: 0.7555 - val_accuracy: 0.7361\n",
      "Epoch 172/300\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 0.64237\n",
      "144/144 - 0s - loss: 0.4762 - accuracy: 0.8750 - val_loss: 0.6552 - val_accuracy: 0.7917\n",
      "Epoch 173/300\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 0.64237\n",
      "144/144 - 0s - loss: 0.4504 - accuracy: 0.8889 - val_loss: 0.6598 - val_accuracy: 0.7917\n",
      "Epoch 174/300\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 0.64237\n",
      "144/144 - 0s - loss: 0.4419 - accuracy: 0.8681 - val_loss: 0.6700 - val_accuracy: 0.7778\n",
      "Epoch 175/300\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 0.64237\n",
      "144/144 - 0s - loss: 0.4683 - accuracy: 0.8889 - val_loss: 0.6786 - val_accuracy: 0.7361\n",
      "Epoch 176/300\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 0.64237\n",
      "144/144 - 0s - loss: 0.4148 - accuracy: 0.9306 - val_loss: 0.6577 - val_accuracy: 0.7500\n",
      "Epoch 177/300\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 0.64237\n",
      "144/144 - 0s - loss: 0.4380 - accuracy: 0.9167 - val_loss: 0.7135 - val_accuracy: 0.7361\n",
      "Epoch 178/300\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 0.64237\n",
      "144/144 - 0s - loss: 0.4341 - accuracy: 0.8889 - val_loss: 0.6912 - val_accuracy: 0.7500\n",
      "Epoch 179/300\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 0.64237\n",
      "144/144 - 0s - loss: 0.4361 - accuracy: 0.9167 - val_loss: 0.7056 - val_accuracy: 0.7500\n",
      "Epoch 180/300\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 0.64237\n",
      "144/144 - 0s - loss: 0.4439 - accuracy: 0.8889 - val_loss: 0.7245 - val_accuracy: 0.7917\n",
      "Epoch 181/300\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 0.64237\n",
      "144/144 - 0s - loss: 0.4469 - accuracy: 0.9167 - val_loss: 0.6687 - val_accuracy: 0.7917\n",
      "Epoch 182/300\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 0.64237\n",
      "144/144 - 0s - loss: 0.4149 - accuracy: 0.8958 - val_loss: 0.7080 - val_accuracy: 0.8056\n",
      "Epoch 183/300\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 0.64237\n",
      "144/144 - 0s - loss: 0.4097 - accuracy: 0.9236 - val_loss: 0.6607 - val_accuracy: 0.7361\n",
      "Epoch 184/300\n",
      "\n",
      "Epoch 00184: val_loss improved from 0.64237 to 0.63324, saving model to /tmp/checkpoint.h5\n",
      "144/144 - 0s - loss: 0.3961 - accuracy: 0.9306 - val_loss: 0.6332 - val_accuracy: 0.7500\n",
      "Epoch 185/300\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 0.63324\n",
      "144/144 - 0s - loss: 0.4078 - accuracy: 0.9028 - val_loss: 0.6942 - val_accuracy: 0.7361\n",
      "Epoch 186/300\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 0.63324\n",
      "144/144 - 0s - loss: 0.4293 - accuracy: 0.8958 - val_loss: 0.6382 - val_accuracy: 0.7500\n",
      "Epoch 187/300\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 0.63324\n",
      "144/144 - 0s - loss: 0.4394 - accuracy: 0.8750 - val_loss: 0.7061 - val_accuracy: 0.7639\n",
      "Epoch 188/300\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 0.63324\n",
      "144/144 - 0s - loss: 0.4542 - accuracy: 0.8958 - val_loss: 0.6588 - val_accuracy: 0.7361\n",
      "Epoch 189/300\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 0.63324\n",
      "144/144 - 0s - loss: 0.3946 - accuracy: 0.9236 - val_loss: 0.6390 - val_accuracy: 0.7639\n",
      "Epoch 190/300\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 0.63324\n",
      "144/144 - 0s - loss: 0.4198 - accuracy: 0.9097 - val_loss: 0.7451 - val_accuracy: 0.7500\n",
      "Epoch 191/300\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 0.63324\n",
      "144/144 - 0s - loss: 0.4062 - accuracy: 0.9097 - val_loss: 0.6800 - val_accuracy: 0.7639\n",
      "Epoch 192/300\n",
      "\n",
      "Epoch 00192: val_loss improved from 0.63324 to 0.62735, saving model to /tmp/checkpoint.h5\n",
      "144/144 - 0s - loss: 0.4365 - accuracy: 0.8681 - val_loss: 0.6274 - val_accuracy: 0.7917\n",
      "Epoch 193/300\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 0.62735\n",
      "144/144 - 0s - loss: 0.4121 - accuracy: 0.9097 - val_loss: 0.6799 - val_accuracy: 0.7917\n",
      "Epoch 194/300\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 0.62735\n",
      "144/144 - 0s - loss: 0.4054 - accuracy: 0.9306 - val_loss: 0.6487 - val_accuracy: 0.7917\n",
      "Epoch 195/300\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 0.62735\n",
      "144/144 - 0s - loss: 0.4065 - accuracy: 0.9028 - val_loss: 0.7254 - val_accuracy: 0.7500\n",
      "Epoch 196/300\n",
      "\n",
      "Epoch 00196: val_loss improved from 0.62735 to 0.62735, saving model to /tmp/checkpoint.h5\n",
      "144/144 - 0s - loss: 0.4200 - accuracy: 0.9097 - val_loss: 0.6273 - val_accuracy: 0.7778\n",
      "Epoch 197/300\n",
      "\n",
      "Epoch 00197: val_loss improved from 0.62735 to 0.58994, saving model to /tmp/checkpoint.h5\n",
      "144/144 - 0s - loss: 0.3861 - accuracy: 0.9514 - val_loss: 0.5899 - val_accuracy: 0.8194\n",
      "Epoch 198/300\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 0.58994\n",
      "144/144 - 0s - loss: 0.3619 - accuracy: 0.9306 - val_loss: 0.6329 - val_accuracy: 0.8056\n",
      "Epoch 199/300\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 0.58994\n",
      "144/144 - 0s - loss: 0.3736 - accuracy: 0.9306 - val_loss: 0.6535 - val_accuracy: 0.7917\n",
      "Epoch 200/300\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 0.58994\n",
      "144/144 - 0s - loss: 0.3777 - accuracy: 0.8889 - val_loss: 0.6557 - val_accuracy: 0.7778\n",
      "Epoch 201/300\n",
      "\n",
      "Epoch 00201: val_loss did not improve from 0.58994\n",
      "144/144 - 0s - loss: 0.3679 - accuracy: 0.9375 - val_loss: 0.6645 - val_accuracy: 0.7500\n",
      "Epoch 202/300\n",
      "\n",
      "Epoch 00202: val_loss did not improve from 0.58994\n",
      "144/144 - 0s - loss: 0.3713 - accuracy: 0.9306 - val_loss: 0.6794 - val_accuracy: 0.7778\n",
      "Epoch 203/300\n",
      "\n",
      "Epoch 00203: val_loss did not improve from 0.58994\n",
      "144/144 - 0s - loss: 0.4194 - accuracy: 0.8889 - val_loss: 0.6423 - val_accuracy: 0.7639\n",
      "Epoch 204/300\n",
      "\n",
      "Epoch 00204: val_loss did not improve from 0.58994\n",
      "144/144 - 0s - loss: 0.4079 - accuracy: 0.8750 - val_loss: 0.6869 - val_accuracy: 0.7778\n",
      "Epoch 205/300\n",
      "\n",
      "Epoch 00205: val_loss did not improve from 0.58994\n",
      "144/144 - 0s - loss: 0.3647 - accuracy: 0.9236 - val_loss: 0.6929 - val_accuracy: 0.7917\n",
      "Epoch 206/300\n",
      "\n",
      "Epoch 00206: val_loss did not improve from 0.58994\n",
      "144/144 - 0s - loss: 0.3807 - accuracy: 0.9028 - val_loss: 0.6250 - val_accuracy: 0.7778\n",
      "Epoch 207/300\n",
      "\n",
      "Epoch 00207: val_loss did not improve from 0.58994\n",
      "144/144 - 0s - loss: 0.3746 - accuracy: 0.9306 - val_loss: 0.6522 - val_accuracy: 0.7639\n",
      "Epoch 208/300\n",
      "\n",
      "Epoch 00208: val_loss did not improve from 0.58994\n",
      "144/144 - 0s - loss: 0.3573 - accuracy: 0.9167 - val_loss: 0.6136 - val_accuracy: 0.7917\n",
      "Epoch 209/300\n",
      "\n",
      "Epoch 00209: val_loss did not improve from 0.58994\n",
      "144/144 - 0s - loss: 0.3492 - accuracy: 0.9167 - val_loss: 0.6329 - val_accuracy: 0.8194\n",
      "Epoch 210/300\n",
      "\n",
      "Epoch 00210: val_loss did not improve from 0.58994\n",
      "144/144 - 0s - loss: 0.3352 - accuracy: 0.9306 - val_loss: 0.6899 - val_accuracy: 0.7500\n",
      "Epoch 211/300\n",
      "\n",
      "Epoch 00211: val_loss did not improve from 0.58994\n",
      "144/144 - 0s - loss: 0.3729 - accuracy: 0.9167 - val_loss: 0.6511 - val_accuracy: 0.7778\n",
      "Epoch 212/300\n",
      "\n",
      "Epoch 00212: val_loss did not improve from 0.58994\n",
      "144/144 - 0s - loss: 0.3416 - accuracy: 0.9514 - val_loss: 0.6531 - val_accuracy: 0.8194\n",
      "Epoch 213/300\n",
      "\n",
      "Epoch 00213: val_loss did not improve from 0.58994\n",
      "144/144 - 0s - loss: 0.3800 - accuracy: 0.8889 - val_loss: 0.6695 - val_accuracy: 0.7778\n",
      "Epoch 214/300\n",
      "\n",
      "Epoch 00214: val_loss did not improve from 0.58994\n",
      "144/144 - 0s - loss: 0.3463 - accuracy: 0.9306 - val_loss: 0.7720 - val_accuracy: 0.7222\n",
      "Epoch 215/300\n",
      "\n",
      "Epoch 00215: val_loss did not improve from 0.58994\n",
      "144/144 - 0s - loss: 0.3390 - accuracy: 0.9514 - val_loss: 0.6375 - val_accuracy: 0.8194\n",
      "Epoch 216/300\n",
      "\n",
      "Epoch 00216: val_loss did not improve from 0.58994\n",
      "144/144 - 0s - loss: 0.3261 - accuracy: 0.9444 - val_loss: 0.6454 - val_accuracy: 0.7639\n",
      "Epoch 217/300\n",
      "\n",
      "Epoch 00217: val_loss did not improve from 0.58994\n",
      "144/144 - 0s - loss: 0.3470 - accuracy: 0.9306 - val_loss: 0.6460 - val_accuracy: 0.8056\n",
      "Epoch 218/300\n",
      "\n",
      "Epoch 00218: val_loss did not improve from 0.58994\n",
      "144/144 - 0s - loss: 0.3488 - accuracy: 0.9444 - val_loss: 0.6356 - val_accuracy: 0.8056\n",
      "Epoch 219/300\n",
      "\n",
      "Epoch 00219: val_loss did not improve from 0.58994\n",
      "144/144 - 0s - loss: 0.2888 - accuracy: 0.9653 - val_loss: 0.6393 - val_accuracy: 0.7639\n",
      "Epoch 220/300\n",
      "\n",
      "Epoch 00220: val_loss did not improve from 0.58994\n",
      "144/144 - 0s - loss: 0.3334 - accuracy: 0.9514 - val_loss: 0.6389 - val_accuracy: 0.7639\n",
      "Epoch 221/300\n",
      "\n",
      "Epoch 00221: val_loss did not improve from 0.58994\n",
      "144/144 - 0s - loss: 0.3649 - accuracy: 0.9028 - val_loss: 0.6448 - val_accuracy: 0.8333\n",
      "Epoch 222/300\n",
      "\n",
      "Epoch 00222: val_loss did not improve from 0.58994\n",
      "144/144 - 0s - loss: 0.3766 - accuracy: 0.8889 - val_loss: 0.6152 - val_accuracy: 0.8056\n",
      "Epoch 223/300\n",
      "\n",
      "Epoch 00223: val_loss did not improve from 0.58994\n",
      "144/144 - 0s - loss: 0.3867 - accuracy: 0.8750 - val_loss: 0.6197 - val_accuracy: 0.7778\n",
      "Epoch 224/300\n",
      "\n",
      "Epoch 00224: val_loss did not improve from 0.58994\n",
      "144/144 - 0s - loss: 0.3430 - accuracy: 0.9306 - val_loss: 0.6070 - val_accuracy: 0.7917\n",
      "Epoch 225/300\n",
      "\n",
      "Epoch 00225: val_loss did not improve from 0.58994\n",
      "144/144 - 0s - loss: 0.3575 - accuracy: 0.9306 - val_loss: 0.6039 - val_accuracy: 0.7639\n",
      "Epoch 226/300\n",
      "\n",
      "Epoch 00226: val_loss did not improve from 0.58994\n",
      "144/144 - 0s - loss: 0.3227 - accuracy: 0.9514 - val_loss: 0.6325 - val_accuracy: 0.8194\n",
      "Epoch 227/300\n",
      "\n",
      "Epoch 00227: val_loss did not improve from 0.58994\n",
      "144/144 - 0s - loss: 0.3307 - accuracy: 0.9097 - val_loss: 0.6321 - val_accuracy: 0.8194\n",
      "Epoch 228/300\n",
      "\n",
      "Epoch 00228: val_loss did not improve from 0.58994\n",
      "144/144 - 0s - loss: 0.3398 - accuracy: 0.9444 - val_loss: 0.6341 - val_accuracy: 0.8333\n",
      "Epoch 229/300\n",
      "\n",
      "Epoch 00229: val_loss improved from 0.58994 to 0.58030, saving model to /tmp/checkpoint.h5\n",
      "144/144 - 0s - loss: 0.3609 - accuracy: 0.9167 - val_loss: 0.5803 - val_accuracy: 0.8194\n",
      "Epoch 230/300\n",
      "\n",
      "Epoch 00230: val_loss did not improve from 0.58030\n",
      "144/144 - 0s - loss: 0.3167 - accuracy: 0.9514 - val_loss: 0.5834 - val_accuracy: 0.8333\n",
      "Epoch 231/300\n",
      "\n",
      "Epoch 00231: val_loss improved from 0.58030 to 0.56271, saving model to /tmp/checkpoint.h5\n",
      "144/144 - 0s - loss: 0.3354 - accuracy: 0.9097 - val_loss: 0.5627 - val_accuracy: 0.8333\n",
      "Epoch 232/300\n",
      "\n",
      "Epoch 00232: val_loss did not improve from 0.56271\n",
      "144/144 - 0s - loss: 0.2934 - accuracy: 0.9653 - val_loss: 0.6007 - val_accuracy: 0.8333\n",
      "Epoch 233/300\n",
      "\n",
      "Epoch 00233: val_loss did not improve from 0.56271\n",
      "144/144 - 0s - loss: 0.3194 - accuracy: 0.9375 - val_loss: 0.6457 - val_accuracy: 0.8333\n",
      "Epoch 234/300\n",
      "\n",
      "Epoch 00234: val_loss did not improve from 0.56271\n",
      "144/144 - 0s - loss: 0.3346 - accuracy: 0.9375 - val_loss: 0.5845 - val_accuracy: 0.8333\n",
      "Epoch 235/300\n",
      "\n",
      "Epoch 00235: val_loss improved from 0.56271 to 0.55610, saving model to /tmp/checkpoint.h5\n",
      "144/144 - 0s - loss: 0.3583 - accuracy: 0.8958 - val_loss: 0.5561 - val_accuracy: 0.7917\n",
      "Epoch 236/300\n",
      "\n",
      "Epoch 00236: val_loss did not improve from 0.55610\n",
      "144/144 - 0s - loss: 0.3709 - accuracy: 0.8889 - val_loss: 0.5972 - val_accuracy: 0.7917\n",
      "Epoch 237/300\n",
      "\n",
      "Epoch 00237: val_loss did not improve from 0.55610\n",
      "144/144 - 0s - loss: 0.3608 - accuracy: 0.9167 - val_loss: 0.6945 - val_accuracy: 0.7639\n",
      "Epoch 238/300\n",
      "\n",
      "Epoch 00238: val_loss did not improve from 0.55610\n",
      "144/144 - 0s - loss: 0.3134 - accuracy: 0.9375 - val_loss: 0.6364 - val_accuracy: 0.7639\n",
      "Epoch 239/300\n",
      "\n",
      "Epoch 00239: val_loss improved from 0.55610 to 0.55399, saving model to /tmp/checkpoint.h5\n",
      "144/144 - 0s - loss: 0.3274 - accuracy: 0.9306 - val_loss: 0.5540 - val_accuracy: 0.8750\n",
      "Epoch 240/300\n",
      "\n",
      "Epoch 00240: val_loss improved from 0.55399 to 0.52486, saving model to /tmp/checkpoint.h5\n",
      "144/144 - 0s - loss: 0.3357 - accuracy: 0.9514 - val_loss: 0.5249 - val_accuracy: 0.8472\n",
      "Epoch 241/300\n",
      "\n",
      "Epoch 00241: val_loss did not improve from 0.52486\n",
      "144/144 - 0s - loss: 0.3469 - accuracy: 0.9028 - val_loss: 0.6082 - val_accuracy: 0.8194\n",
      "Epoch 242/300\n",
      "\n",
      "Epoch 00242: val_loss did not improve from 0.52486\n",
      "144/144 - 0s - loss: 0.3166 - accuracy: 0.9306 - val_loss: 0.5860 - val_accuracy: 0.8333\n",
      "Epoch 243/300\n",
      "\n",
      "Epoch 00243: val_loss did not improve from 0.52486\n",
      "144/144 - 0s - loss: 0.3350 - accuracy: 0.9097 - val_loss: 0.5946 - val_accuracy: 0.8194\n",
      "Epoch 244/300\n",
      "\n",
      "Epoch 00244: val_loss did not improve from 0.52486\n",
      "144/144 - 0s - loss: 0.3330 - accuracy: 0.9236 - val_loss: 0.5717 - val_accuracy: 0.8472\n",
      "Epoch 245/300\n",
      "\n",
      "Epoch 00245: val_loss did not improve from 0.52486\n",
      "144/144 - 0s - loss: 0.2949 - accuracy: 0.9306 - val_loss: 0.6083 - val_accuracy: 0.7639\n",
      "Epoch 246/300\n",
      "\n",
      "Epoch 00246: val_loss did not improve from 0.52486\n",
      "144/144 - 0s - loss: 0.3487 - accuracy: 0.9167 - val_loss: 0.6319 - val_accuracy: 0.7917\n",
      "Epoch 247/300\n",
      "\n",
      "Epoch 00247: val_loss did not improve from 0.52486\n",
      "144/144 - 0s - loss: 0.3717 - accuracy: 0.9236 - val_loss: 0.6096 - val_accuracy: 0.8333\n",
      "Epoch 248/300\n",
      "\n",
      "Epoch 00248: val_loss did not improve from 0.52486\n",
      "144/144 - 0s - loss: 0.3651 - accuracy: 0.9236 - val_loss: 0.6101 - val_accuracy: 0.8472\n",
      "Epoch 249/300\n",
      "\n",
      "Epoch 00249: val_loss did not improve from 0.52486\n",
      "144/144 - 0s - loss: 0.3402 - accuracy: 0.9028 - val_loss: 0.6244 - val_accuracy: 0.7500\n",
      "Epoch 250/300\n",
      "\n",
      "Epoch 00250: val_loss did not improve from 0.52486\n",
      "144/144 - 0s - loss: 0.3406 - accuracy: 0.8958 - val_loss: 0.5972 - val_accuracy: 0.7778\n",
      "Epoch 251/300\n",
      "\n",
      "Epoch 00251: val_loss did not improve from 0.52486\n",
      "144/144 - 0s - loss: 0.3094 - accuracy: 0.9306 - val_loss: 0.5752 - val_accuracy: 0.8611\n",
      "Epoch 252/300\n",
      "\n",
      "Epoch 00252: val_loss did not improve from 0.52486\n",
      "144/144 - 0s - loss: 0.3293 - accuracy: 0.9236 - val_loss: 0.5714 - val_accuracy: 0.8333\n",
      "Epoch 253/300\n",
      "\n",
      "Epoch 00253: val_loss did not improve from 0.52486\n",
      "144/144 - 0s - loss: 0.2853 - accuracy: 0.9306 - val_loss: 0.5629 - val_accuracy: 0.8194\n",
      "Epoch 254/300\n",
      "\n",
      "Epoch 00254: val_loss did not improve from 0.52486\n",
      "144/144 - 0s - loss: 0.3336 - accuracy: 0.9167 - val_loss: 0.5891 - val_accuracy: 0.7917\n",
      "Epoch 255/300\n",
      "\n",
      "Epoch 00255: val_loss did not improve from 0.52486\n",
      "144/144 - 0s - loss: 0.2913 - accuracy: 0.9653 - val_loss: 0.5811 - val_accuracy: 0.7917\n",
      "Epoch 256/300\n",
      "\n",
      "Epoch 00256: val_loss did not improve from 0.52486\n",
      "144/144 - 0s - loss: 0.3115 - accuracy: 0.9375 - val_loss: 0.5663 - val_accuracy: 0.8194\n",
      "Epoch 257/300\n",
      "\n",
      "Epoch 00257: val_loss did not improve from 0.52486\n",
      "144/144 - 0s - loss: 0.2902 - accuracy: 0.9375 - val_loss: 0.5348 - val_accuracy: 0.8472\n",
      "Epoch 258/300\n",
      "\n",
      "Epoch 00258: val_loss did not improve from 0.52486\n",
      "144/144 - 0s - loss: 0.3083 - accuracy: 0.9375 - val_loss: 0.5772 - val_accuracy: 0.8333\n",
      "Epoch 259/300\n",
      "\n",
      "Epoch 00259: val_loss did not improve from 0.52486\n",
      "144/144 - 0s - loss: 0.3474 - accuracy: 0.9306 - val_loss: 0.5399 - val_accuracy: 0.8194\n",
      "Epoch 260/300\n",
      "\n",
      "Epoch 00260: val_loss did not improve from 0.52486\n",
      "144/144 - 0s - loss: 0.3078 - accuracy: 0.9236 - val_loss: 0.5415 - val_accuracy: 0.8056\n",
      "Epoch 261/300\n",
      "\n",
      "Epoch 00261: val_loss did not improve from 0.52486\n",
      "144/144 - 0s - loss: 0.3372 - accuracy: 0.9306 - val_loss: 0.5872 - val_accuracy: 0.8056\n",
      "Epoch 262/300\n",
      "\n",
      "Epoch 00262: val_loss did not improve from 0.52486\n",
      "144/144 - 0s - loss: 0.3138 - accuracy: 0.9375 - val_loss: 0.5961 - val_accuracy: 0.8333\n",
      "Epoch 263/300\n",
      "\n",
      "Epoch 00263: val_loss did not improve from 0.52486\n",
      "144/144 - 0s - loss: 0.3323 - accuracy: 0.9167 - val_loss: 0.6195 - val_accuracy: 0.8056\n",
      "Epoch 264/300\n",
      "\n",
      "Epoch 00264: val_loss did not improve from 0.52486\n",
      "144/144 - 0s - loss: 0.3327 - accuracy: 0.9375 - val_loss: 0.5397 - val_accuracy: 0.8750\n",
      "Epoch 265/300\n",
      "\n",
      "Epoch 00265: val_loss improved from 0.52486 to 0.52080, saving model to /tmp/checkpoint.h5\n",
      "144/144 - 0s - loss: 0.2793 - accuracy: 0.9375 - val_loss: 0.5208 - val_accuracy: 0.8750\n",
      "Epoch 266/300\n",
      "\n",
      "Epoch 00266: val_loss improved from 0.52080 to 0.49705, saving model to /tmp/checkpoint.h5\n",
      "144/144 - 0s - loss: 0.2651 - accuracy: 0.9653 - val_loss: 0.4971 - val_accuracy: 0.8750\n",
      "Epoch 267/300\n",
      "\n",
      "Epoch 00267: val_loss did not improve from 0.49705\n",
      "144/144 - 0s - loss: 0.2916 - accuracy: 0.9375 - val_loss: 0.5605 - val_accuracy: 0.8611\n",
      "Epoch 268/300\n",
      "\n",
      "Epoch 00268: val_loss did not improve from 0.49705\n",
      "144/144 - 0s - loss: 0.2698 - accuracy: 0.9583 - val_loss: 0.5192 - val_accuracy: 0.8611\n",
      "Epoch 269/300\n",
      "\n",
      "Epoch 00269: val_loss did not improve from 0.49705\n",
      "144/144 - 0s - loss: 0.2728 - accuracy: 0.9514 - val_loss: 0.5649 - val_accuracy: 0.8472\n",
      "Epoch 270/300\n",
      "\n",
      "Epoch 00270: val_loss did not improve from 0.49705\n",
      "144/144 - 0s - loss: 0.3649 - accuracy: 0.8958 - val_loss: 0.6128 - val_accuracy: 0.8472\n",
      "Epoch 271/300\n",
      "\n",
      "Epoch 00271: val_loss did not improve from 0.49705\n",
      "144/144 - 0s - loss: 0.2634 - accuracy: 0.9653 - val_loss: 0.5609 - val_accuracy: 0.8194\n",
      "Epoch 272/300\n",
      "\n",
      "Epoch 00272: val_loss did not improve from 0.49705\n",
      "144/144 - 0s - loss: 0.2601 - accuracy: 0.9514 - val_loss: 0.6216 - val_accuracy: 0.7778\n",
      "Epoch 273/300\n",
      "\n",
      "Epoch 00273: val_loss did not improve from 0.49705\n",
      "144/144 - 0s - loss: 0.2506 - accuracy: 0.9653 - val_loss: 0.5733 - val_accuracy: 0.8750\n",
      "Epoch 274/300\n",
      "\n",
      "Epoch 00274: val_loss did not improve from 0.49705\n",
      "144/144 - 0s - loss: 0.3032 - accuracy: 0.9167 - val_loss: 0.6219 - val_accuracy: 0.8333\n",
      "Epoch 275/300\n",
      "\n",
      "Epoch 00275: val_loss did not improve from 0.49705\n",
      "144/144 - 0s - loss: 0.3286 - accuracy: 0.8958 - val_loss: 0.5693 - val_accuracy: 0.8056\n",
      "Epoch 276/300\n",
      "\n",
      "Epoch 00276: val_loss did not improve from 0.49705\n",
      "144/144 - 0s - loss: 0.2913 - accuracy: 0.9306 - val_loss: 0.6049 - val_accuracy: 0.8333\n",
      "Epoch 277/300\n",
      "\n",
      "Epoch 00277: val_loss did not improve from 0.49705\n",
      "144/144 - 0s - loss: 0.2596 - accuracy: 0.9375 - val_loss: 0.5481 - val_accuracy: 0.8889\n",
      "Epoch 278/300\n",
      "\n",
      "Epoch 00278: val_loss did not improve from 0.49705\n",
      "144/144 - 0s - loss: 0.2495 - accuracy: 0.9653 - val_loss: 0.5376 - val_accuracy: 0.8611\n",
      "Epoch 279/300\n",
      "\n",
      "Epoch 00279: val_loss did not improve from 0.49705\n",
      "144/144 - 0s - loss: 0.2727 - accuracy: 0.9514 - val_loss: 0.6096 - val_accuracy: 0.8333\n",
      "Epoch 280/300\n",
      "\n",
      "Epoch 00280: val_loss did not improve from 0.49705\n",
      "144/144 - 0s - loss: 0.2357 - accuracy: 0.9653 - val_loss: 0.6222 - val_accuracy: 0.8056\n",
      "Epoch 281/300\n",
      "\n",
      "Epoch 00281: val_loss did not improve from 0.49705\n",
      "144/144 - 0s - loss: 0.2637 - accuracy: 0.9514 - val_loss: 0.5850 - val_accuracy: 0.8333\n",
      "Epoch 282/300\n",
      "\n",
      "Epoch 00282: val_loss did not improve from 0.49705\n",
      "144/144 - 0s - loss: 0.2464 - accuracy: 0.9444 - val_loss: 0.5518 - val_accuracy: 0.8333\n",
      "Epoch 283/300\n",
      "\n",
      "Epoch 00283: val_loss did not improve from 0.49705\n",
      "144/144 - 0s - loss: 0.2506 - accuracy: 0.9583 - val_loss: 0.6005 - val_accuracy: 0.7917\n",
      "Epoch 284/300\n",
      "\n",
      "Epoch 00284: val_loss did not improve from 0.49705\n",
      "144/144 - 0s - loss: 0.3007 - accuracy: 0.9236 - val_loss: 0.5974 - val_accuracy: 0.8194\n",
      "Epoch 285/300\n",
      "\n",
      "Epoch 00285: val_loss did not improve from 0.49705\n",
      "144/144 - 0s - loss: 0.2763 - accuracy: 0.9514 - val_loss: 0.6222 - val_accuracy: 0.8611\n",
      "Epoch 286/300\n",
      "\n",
      "Epoch 00286: val_loss did not improve from 0.49705\n",
      "144/144 - 0s - loss: 0.3183 - accuracy: 0.9028 - val_loss: 0.5335 - val_accuracy: 0.8472\n",
      "Epoch 287/300\n",
      "\n",
      "Epoch 00287: val_loss did not improve from 0.49705\n",
      "144/144 - 0s - loss: 0.2591 - accuracy: 0.9514 - val_loss: 0.5638 - val_accuracy: 0.8194\n",
      "Epoch 288/300\n",
      "\n",
      "Epoch 00288: val_loss did not improve from 0.49705\n",
      "144/144 - 0s - loss: 0.2465 - accuracy: 0.9653 - val_loss: 0.5721 - val_accuracy: 0.8472\n",
      "Epoch 289/300\n",
      "\n",
      "Epoch 00289: val_loss did not improve from 0.49705\n",
      "144/144 - 0s - loss: 0.3296 - accuracy: 0.9236 - val_loss: 0.5721 - val_accuracy: 0.8194\n",
      "Epoch 290/300\n",
      "\n",
      "Epoch 00290: val_loss did not improve from 0.49705\n",
      "144/144 - 0s - loss: 0.2703 - accuracy: 0.9236 - val_loss: 0.5348 - val_accuracy: 0.8056\n",
      "Epoch 291/300\n",
      "\n",
      "Epoch 00291: val_loss did not improve from 0.49705\n",
      "144/144 - 0s - loss: 0.2567 - accuracy: 0.9514 - val_loss: 0.6532 - val_accuracy: 0.8194\n",
      "Epoch 292/300\n",
      "\n",
      "Epoch 00292: val_loss did not improve from 0.49705\n",
      "144/144 - 0s - loss: 0.3421 - accuracy: 0.9028 - val_loss: 0.5720 - val_accuracy: 0.8472\n",
      "Epoch 293/300\n",
      "\n",
      "Epoch 00293: val_loss did not improve from 0.49705\n",
      "144/144 - 0s - loss: 0.2666 - accuracy: 0.9514 - val_loss: 0.5267 - val_accuracy: 0.9028\n",
      "Epoch 294/300\n",
      "\n",
      "Epoch 00294: val_loss did not improve from 0.49705\n",
      "144/144 - 0s - loss: 0.2079 - accuracy: 0.9583 - val_loss: 0.6185 - val_accuracy: 0.8194\n",
      "Epoch 295/300\n",
      "\n",
      "Epoch 00295: val_loss did not improve from 0.49705\n",
      "144/144 - 0s - loss: 0.2320 - accuracy: 0.9653 - val_loss: 0.5803 - val_accuracy: 0.8194\n",
      "Epoch 296/300\n",
      "\n",
      "Epoch 00296: val_loss did not improve from 0.49705\n",
      "144/144 - 0s - loss: 0.2035 - accuracy: 0.9792 - val_loss: 0.6069 - val_accuracy: 0.8333\n",
      "Epoch 297/300\n",
      "\n",
      "Epoch 00297: val_loss did not improve from 0.49705\n",
      "144/144 - 0s - loss: 0.2349 - accuracy: 0.9583 - val_loss: 0.5377 - val_accuracy: 0.8611\n",
      "Epoch 298/300\n",
      "\n",
      "Epoch 00298: val_loss did not improve from 0.49705\n",
      "144/144 - 0s - loss: 0.2717 - accuracy: 0.9444 - val_loss: 0.5630 - val_accuracy: 0.8333\n",
      "Epoch 299/300\n",
      "\n",
      "Epoch 00299: val_loss did not improve from 0.49705\n",
      "144/144 - 0s - loss: 0.2298 - accuracy: 0.9444 - val_loss: 0.5227 - val_accuracy: 0.8333\n",
      "Epoch 300/300\n",
      "\n",
      "Epoch 00300: val_loss did not improve from 0.49705\n",
      "144/144 - 0s - loss: 0.2410 - accuracy: 0.9653 - val_loss: 0.5362 - val_accuracy: 0.8333\n",
      "Classification accuracy: 0.916667 \n"
     ]
    }
   ],
   "source": [
    "###############################################################################\n",
    "# if the classification task was imbalanced (significantly more trials in one\n",
    "# class versus the others) you can assign a weight to each class during\n",
    "# optimization to balance it out. This data is approximately balanced so we\n",
    "# don't need to do this, but is shown here for illustration/completeness.\n",
    "###############################################################################\n",
    "\n",
    "# the syntax is {class_1:weight_1, class_2:weight_2,...}. Here just setting\n",
    "# the weights all to be 1\n",
    "class_weights = {0: 1, 1: 1, 2: 1, 3: 1}\n",
    "\n",
    "################################################################################\n",
    "# fit the model. Due to very small sample sizes this can get\n",
    "# pretty noisy run-to-run, but most runs should be comparable to xDAWN +\n",
    "# Riemannian geometry classification (below)\n",
    "################################################################################\n",
    "fittedModel = model.fit(X_train, Y_train, batch_size=16, epochs=300,\n",
    "                        verbose=2, validation_data=(X_validate, Y_validate),\n",
    "                        callbacks=[checkpointer], class_weight=class_weights)\n",
    "\n",
    "# load optimal weights\n",
    "model.load_weights('/tmp/checkpoint.h5')\n",
    "\n",
    "###############################################################################\n",
    "# can alternatively used the weights provided in the repo. If so it should get\n",
    "# you 93% accuracy. Change the WEIGHTS_PATH variable to wherever it is on your\n",
    "# system.\n",
    "###############################################################################\n",
    "\n",
    "# WEIGHTS_PATH = /path/to/EEGNet-8-2-weights.h5\n",
    "# model.load_weights(WEIGHTS_PATH)\n",
    "\n",
    "###############################################################################\n",
    "# make prediction on test set.\n",
    "###############################################################################\n",
    "\n",
    "probs = model.predict(X_test)\n",
    "preds = probs.argmax(axis=-1)\n",
    "acc = np.mean(preds == Y_test.argmax(axis=-1))\n",
    "print(\"Classification accuracy: %f \" % (acc))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification accuracy: 0.944444 \n"
     ]
    },
    {
     "data": {
      "text/plain": "<matplotlib.axes._subplots.AxesSubplot at 0x22d4ad63eb8>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 2 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 2 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "############################# PyRiemann Portion ##############################\n",
    "\n",
    "# code is taken from PyRiemann's ERP sample script, which is decoding in\n",
    "# the tangent space with a logistic regression\n",
    "\n",
    "n_components = 2  # pick some components\n",
    "\n",
    "# set up sklearn pipeline\n",
    "clf = make_pipeline(XdawnCovariances(n_components),\n",
    "                    TangentSpace(metric='riemann'),\n",
    "                    LogisticRegression())\n",
    "\n",
    "preds_rg = np.zeros(len(Y_test))\n",
    "\n",
    "# reshape back to (trials, channels, samples)\n",
    "X_train = X_train.reshape(X_train.shape[0], chans, samples)\n",
    "X_test = X_test.reshape(X_test.shape[0], chans, samples)\n",
    "\n",
    "# train a classifier with xDAWN spatial filtering + Riemannian Geometry (RG)\n",
    "# labels need to be back in single-column format\n",
    "clf.fit(X_train, Y_train.argmax(axis=-1))\n",
    "preds_rg = clf.predict(X_test)\n",
    "\n",
    "# Printing the results\n",
    "acc2 = np.mean(preds_rg == Y_test.argmax(axis=-1))\n",
    "print(\"Classification accuracy: %f \" % (acc2))\n",
    "\n",
    "# plot the confusion matrices for both classifiers\n",
    "names = ['audio left', 'audio right', 'vis left', 'vis right']\n",
    "plt.figure(0)\n",
    "plot_confusion_matrix(preds, Y_test.argmax(axis=-1), names, title='EEGNet-8,2')\n",
    "\n",
    "plt.figure(1)\n",
    "plot_confusion_matrix(preds_rg, Y_test.argmax(axis=-1), names, title='xDAWN + RG')\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}